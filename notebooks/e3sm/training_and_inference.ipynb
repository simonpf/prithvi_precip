{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c5ef81f-394b-4bca-93db-805a085bc423",
   "metadata": {},
   "source": [
    "# Training and inference\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c609ae1f-1cb8-44a8-9768-91cd7149b210",
   "metadata": {},
   "source": [
    "## Model overview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08c5494-e8e4-4140-9c9f-f543c11c628a",
   "metadata": {},
   "source": [
    "## Running the training\n",
    "\n",
    "### Using ``pytorch_retrieve``\n",
    "\n",
    "A simple training recipe for the Prithvi-WxC using the ``pytorch_retrieve`` package is provided in the ``model_small`` directory. The directory contains three files ``model.toml``, ``training.toml``, and ``compute.toml``, which describe the model configuration, training schedule, and compute configuration, respectively. The training can be run by executing the ``pytroch_retrieve train`` command in the ``model_small`` directory.\n",
    "\n",
    "````\n",
    "cd model_small\n",
    "pytorch_retrieve train\n",
    "````\n",
    "\n",
    "### Manual training\n",
    "\n",
    "For more fine-grained control over training, the ``PrithviWxCRegional`` model can be instantiated directly yielding a PyTorch module that can be trained using PyTorch or lightning.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57930987-884e-4794-9b44-9b98831b5650",
   "metadata": {},
   "source": [
    "The training process can be monitored using ``tensorboard --logdir logs``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d360e44-dbd2-45cb-ae57-603b0f08d560",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from PrithviWxC.dataloaders.merra2 import (\n",
    "    input_scalers,\n",
    "    output_scalers,\n",
    "    static_input_scalers,\n",
    ")\n",
    "from pytorch_retrieve.models.prithvi_wxc import PrithviWxCRegional\n",
    "\n",
    "VERTICAL_VARS = [\"CLOUD\", \"H\", \"OMEGA\", \"PL\", \"QI\", \"QL\", \"QV\", \"T\", \"U\", \"V\"]\n",
    "STATIC_SURFACE_VARS = [\"FRACI\", \"FRLAND\", \"FROCEAN\", \"PHIS\"]\n",
    "SURFACE_VARS = [\n",
    "    \"EFLUX\", \"GWETROOT\", \"HFLUX\", \"LAI\", \"LWGAB\", \"LWGEM\", \"LWTUP\", \"PS\", \"QV2M\", \"SLP\",\n",
    "    \"SWGNT\", \"SWTNT\", \"T2M\", \"TQI\", \"TQL\", \"TQV\", \"TS\", \"U10M\", \"V10M\", \"Z0M\"\n",
    "]\n",
    "LEVELS = [\n",
    "    34.0, 39.0, 41.0, 43.0, 44.0, 45.0, 48.0, 51.0, 53.0, 56.0, 63.0, 68.0, 71.0, 72.0\n",
    "]\n",
    "\n",
    "# Path containing the scaling factors\n",
    "scaling_factors = Path(\"/home/simon/data/e3sm/scaling_factors\")\n",
    "in_mu, in_sig = input_scalers(\n",
    "    SURFACE_VARS,\n",
    "    VERTICAL_VARS,\n",
    "    LEVELS,\n",
    "    str(scaling_factors / \"musigma_surface.nc\"),\n",
    "    str(scaling_factors / \"musigma_vertical.nc\"),\n",
    ")\n",
    "output_sig = output_scalers(\n",
    "    SURFACE_VARS,\n",
    "    VERTICAL_VARS,\n",
    "    LEVELS,\n",
    "    str(scaling_factors / \"anomaly_variance_surface.nc\"),\n",
    "    str(scaling_factors / \"anomaly_variance_vertical.nc\"),\n",
    ")\n",
    "\n",
    "static_mu, static_sig = static_input_scalers(\n",
    "    str(scaling_factors / \"musigma_surface.nc\"),\n",
    "    STATIC_SURFACE_VARS,\n",
    ")\n",
    "\n",
    "# Parameters are chosen to match the small Prithvi-WxC model.\n",
    "model = PrithviWxCRegional(\n",
    "    in_channels=160,\n",
    "    input_size_time=2,\n",
    "    in_channels_static=8,\n",
    "    input_scalers_epsilon=0.0,\n",
    "    static_input_scalers_epsilon=0.0,\n",
    "    n_lats_px=180,\n",
    "    n_lons_px=360,\n",
    "    patch_size_px=[2, 2],\n",
    "    mask_unit_size_px=[20, 20],\n",
    "    embed_dim=1024,\n",
    "    n_blocks_encoder=8,\n",
    "    n_blocks_decoder=4,\n",
    "    mlp_multiplier=4,\n",
    "    n_heads=16,\n",
    "    dropout=0.0,\n",
    "    drop_path=0.0,\n",
    "    parameter_dropout=0.0,\n",
    "    positional_encoding=\"fourier\",\n",
    "    encoder_shifting=True,\n",
    "    decoder_shifting=False,\n",
    "    mask_ratio_inputs=0.0,\n",
    "    residual=\"climate\",\n",
    "    masking_mode=\"both\",\n",
    "    # Activate activate checpointing to reduce memory footprint.\n",
    "    checkpoint_encoder=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16],\n",
    "    checkpoint_decoder=[0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
    "    input_scalers_mu=in_mu,\n",
    "    input_scalers_sigma=in_sig,\n",
    "    static_input_scalers_mu= static_mu,\n",
    "    static_input_scalers_sigma= static_sig,\n",
    "    output_scalers= output_sig ** 0.5,\n",
    "    mask_ratio_targets=0.0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f4e751-c458-4a73-8fd0-f9b3d5c7cd36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
